Median


Another useful concept is median: the middle value of an ordered dataset.
To calculate the median for our prices dataset, let's first order it in ascending order:

[14, 18, 19, 24, 26, 33, 42, 55, 67]  

The median is 26, as that's the middle value.
If our dataset had an even number of values, we would take the two values in the middle and calculate their average value.
The median is generally more useful than the mean. This is because the mean can vary widely due to one value that is a lot larger or smaller than the others.
The mean and the median are called
Measures of Central Tendency, as they describe where the center of our data is.


Number of Vaccinations

We have a report on the number of flu vaccinations in a class of 20 people.

It has the following numbers:
never: 5
once: 8
twice: 4
3 times: 3

What is the mean number of times those people have been vaccinated?
Output the result using the print() statement.
Hint: Think about the data this way: it contains 20 values, each representing the number of vaccinations the corresponding person had.

vac_nums = [0,0,0,0,0,
            1,1,1,1,1,1,1,1,
            2,2,2,2,
            3,3,3
            ]
#your code goes here

su = 0
count = 0
for v in vac_nums:
    count += 1 
    su += v

print(su/count)


#############################################################


Standard Deviation


The Standard Deviation is a measure of how spread out our data is.

**************************************************To calculate it, we first need to calculate a value called Variance: 

**************************************************which is the average of the squared differences from the mean.
So, for our prices data:
[14, 18, 19, 24, 26, 33, 42, 55, 67] 

**************************************************the mean is 33.1. 
**************************************************To calculate the variance,
**************************************************we take the difference between each value and the mean, square it,
**************************************************and then average the result: Variance = 292.5

Now we take the square root of the Variance, to get the Standard Deviation: std = 17.1

Now, we can check which ages are within one standard deviation (17.1) from the mean (33.1) - from (33.1-17.1) to (33.1+17.1):
[14, 18, 19, 24, 26, 33, 42, 55, 67] 
As you can see, 6 values out of 9 are within that range.
A low standard deviation indicates that the values tend to be close to the mean of the set, while a high standard deviation indicates that the values are spread out over a wider range.


Statistics


We have learned how to calculate the main summary statistics for a data set:
mean: the average of the values.
median: the middle value.
standard deviation: the measure of spread.

These statistics provide information about your data set and help you understand where your data values are and how they are distributed.
Python provides libraries that calculate the summary statistics for you. We will learn about them in later lessons.
icon
Vaccinations Dataset

Number of Vaccinations


Using the same vaccinations dataset, which includes the number of times people got the flu vaccine.
The dataset contains the following numbers:
never: 5
once: 8
twice: 4
3 times: 3

Calculate and output the variance.
We will soon learn about easier ways to calculate the variance and other summary statistics using Python. For now, use Python code to calculate the result using the corresponding equation.
Hint: The variance is the average of the squared differences from the mean.


SOLUTION:


vac_nums = [0,0,0,0,0,
            1,1,1,1,1,1,1,1,
            2,2,2,2,
            3,3,3
            ]
#your code goes here

su = 0
count = 0
vari = 0
variance = 0
for v in vac_nums:
    count += 1 
    su += v

mean = su/count

for var in vac_nums:
    vari += (var-mean)**2

variance = vari/count

print(variance)

############################################################################


Problem

Basketball Players


The given code includes a list of heights for various basketball players.
You need to calculate and output how many players are in the range of one standard deviation from the mean.

Output the result using the print statement.



SOLUTION:


players = [180, 172, 178, 185, 190, 195, 192, 200, 210, 190]


su = 0
count = 0
vari = 0
variance = 0

for v in players:
    count += 1 
    su += v

mean = su/count

for var in players:
    vari += (var-mean)**2

variance = vari/count
square =  variance**0.5
countPlayer = 0


stdDerPos = mean + square
stdDerNeg = mean - square 

for i in players:
    if (i >= stdDerNeg  and i <= stdDerPos):
        countPlayer += 1

print(countPlayer)


#################################################################################################################


NumPy


NumPy (Numerical Python) is a Python library used to work with numerical data.
NumPy includes functions and data structures that can perform a wide variety of mathematical operations.

To start using NumPy, we first need to import it:


*******************import numpy as np 


np is the most common name used to import numpy.



NumPy Array


In Python, lists are used to store data.
NumPy provides an array structure for performing operations with data.
NumPy arrays are faster and more compact than lists.

A NumPy array can be created using the np.array() function, providing it a list as the argument:

x = np.array([1, 2, 3, 4]) 

Now, x is a NumPy array containing 4 values.
We can access its elements using their indexes, which start from 0:

import numpy as np
x = np.array([1, 2, 3, 4])
print(x[0]) 
#1


NumPy arrays are homogeneous, meaning they can contain only a single data type, while lists can contain multiple different types of data.



NumPy Arrays


NumPy arrays are often called ndarrays, which stands for "N-dimensional array", because they can have multiple dimensions.

For Example:
x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
 
print(x[1][2])


This will create a 2-dimensional array, which has 3 columns and 3 rows, and output the value at the 2nd row and 3rd column.

Arrays have properties, which can be accessed using a dot.
ndim returns the number of dimensions of the array.
size returns the total number of elements of the array.
shape returns a tuple of integers that indicate the number of elements stored along each dimension of the array.

For example:
x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) 
print(x.ndim) # 2
print(x.size) # 9
print(x.shape) # (3, 3)

So, the array in our example has 2 dimensions, 9 elements and is a 3x3 matrix (3 rows and 3 columns).


NumPy Arrays


We can add, remove and sort an array using the np.append(), np.delete() and np.sort() functions.

For example:
import numpy as np

x = np.array([2, 1, 3])

x = np.append(x, 4)
x = np.delete(x, 0)
x = np.sort(x)

print(x)

#[1 3 4]

np.arange() allows you to create an array that contains a range of evenly spaced intervals (similar to a Python range):

import numpy as np

x = np.arange(2, 10, 3)
print(x)
[2 5 8]

This will create the array [2, 5, 8]


Reshape


Recall that shape refers to the number of rows and columns in the array.

For example, let's consider the following array:

import numpy as np

x = np.arange(1, 7)
 
print(x)

#[1 2 3 4 5 6]


This is a 1-dimensional array, containing 6 elements.

NumPy allows us to change the shape of our arrays using the reshape() function. For example, we can change our 1-dimensional array to an array with 3 rows and 2 columns:


import numpy as np

x = np.arange(1, 7)

z = x.reshape(3, 2)

print(z)

[[1 2]
 [3 4]
 [5 6]]


 When you use the reshape method, the array you want to produce needs to have the same number of elements as the original array.


Reshape


Reshape can also do the opposite: take a 2-dimensional array and make a 1-dimensional array from it:


import numpy as np

x = np.array([[1, 2], [3, 4], [5, 6]])

print(x)

z = x.reshape(6)

print(z)


#x=
[[1 2]
 [3 4]
 [5 6]]


#z=
[1 2 3 4 5 6]

The result is a flat array that contains 6 elements.

The same result can be achieved using the flatten() function.

Reshape

What is the output of this code?

x = np.arange(1, 8, 3)
z = x.reshape(3, 1)
print(z[1][0])
#4

##################################################################################################

Problem
Seats in a Theater


You are given an array that represents the occupancy of seats in a movie theater. A seat marked with 1 is occupied, while one marked 0 means the seat is free.
However, the array is flat and 1-dimensional. Transform it into a 2-dimensional array, representing the rows of the seats.
Each row in the theater has 5 seats and there are a total of 30 seats.
Reshape the array into the corresponding shape and output the row at the given index, which is taken from user input.
The row index is taken from user input in the given code.


import numpy as np

data = np.array([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0])

row = int(input())

r = data.reshape(6,5)

print(r[row])

##################################################################################################


Indexing and Slicing


NumPy arrays can be indexed and sliced the same way that Python lists are.

For example:
Negative indexes count from the end of the array, so, [-3:] will result in the last 3 elements.

import numpy as np

x = np.arange(1, 10)

print(x)

print("zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz")


print(x[0:2])
print(x[5:])
print(x[:2])
print(x[-3:])


[1 2 3 4 5 6 7 8 9]
zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz
[1 2]
[6 7 8 9]
[1 2]
[7 8 9]


Negative indexes count from the end of the array, so, [-3:] will result in the last 3 elements.


Conditions


You can provide a condition as the index to select the elements that fulfill the given condition.

For example, let's select the elements that are less than 4:

import numpy as np

x = np.arange(1, 10)

print(x[x<4])
[1 2 3]

Conditions can be combined using the & (and) and | (or) operators.
For example, let's take the even numbers that are greater than 5:


import numpy as np

x = np.arange(1, 10)

print(x[(x>5) & (x%2==0)])
#[6 8]



The condition can also be assigned to a variable, which will be an array of boolean values showing whether or not the values in the array fulfill the condition:
y = (x>5) & (x%2==0)

###########################################################################

Operations


It is easy to perform basic mathematical operations with arrays.
For example, to find the sum of all elements, we use the sum() function:

import numpy as np
x = np.arange(1, 10) #[1,2,3,4,5,6,7,8,9]
print(x.sum())
#45


Similarly, min() and max() can be used to get the smallest and largest elements.

We can also perform operations between the array and a single number.
For example, we can multiply all elements by 2:


import numpy as np

x = np.arange(1, 10)
y = x*2

print(y)

[ 2  4  6  8 10 12 14 16 18]

As simple as that! Take your array and perform any operation you want with it!
NumPy understands that the given operation should be performed with each element. This is called broadcasting.

Operations
Fill in the blanks to convert all values in the array from megabytes to kilobytes. (1 megabyte is 1024 kilobytes).
Then, output the largest element.


data_mb = np.array([6, 3, 10, 143])

data_kb = data_mb * 1024

print(data_kb.max())


Statistics


Remember the summary statistics we learned in the previous module? Those included mean, median, variance and standard deviation.

NumPy arrays have built-in functions to return those values.


import numpy as np

x = np.array([14, 18, 19, 24, 26, 33, 42, 55, 67])

print(np.mean(x))
print(np.median(x))
print(np.var(x))
print(np.std(x))


33.111111111111114
26.0
292.5432098765432
17.10389458212787

As you can see, NumPy provides many useful functions to perform common operations with arrays.



Statistics
Fill in the blanks to output the standard deviation for the array 'x'.


res = np.std(x)
print(res)


What is the output?

x = np.arange(3, 9) # [3,4,5,6,7,8]
z = x.reshape(2, 3)

                        [3,4,5,      # line 0
                         6,7,8]      # line 1   
print(z[1][1])
#7


##############################################################################


House Prices

Problem
House Prices


You are given an array that represents house prices.
Calculate and output the percentage of houses that are within one standard deviation from the mean.
To calculate the percentage, divide the number of houses that satisfy the condition by the total number of houses, and multiply the result by 100.


SOLUTION:


import numpy as np

data = np.array([150000, 125000, 320000, 540000, 200000, 120000, 160000, 230000,
                 280000, 290000, 300000, 500000, 420000, 100000, 150000, 280000])


std = np.std(data)
su = 0
count = 0

for c in data:
    count += 1
    su += c

mean = su/count

stdDerPos = mean + std
stdDerNeg = mean - std 

countStd = 0

for i in data:
    if (i >= stdDerNeg  and i <= stdDerPos):
        countStd += 1


percStd = (countStd/count)*100

print(percStd)

###########################################################################################

What is Pandas?


Pandas is one of the most popular data science libraries in Python. Easy to use, it is built on top of NumPy and shares many functions and properties.

With Pandas, you can read and extract data from files, transform and analyze it, calculate statistics and correlations, and much more!

To start using pandas, we need to import it first:
import pandas as pd 


pd is a common short name used when importing the library.


Pandas is derived from the term "panel data", an econometrics term for data sets that include observations over multiple time periods for the same individuals.


Series & DataFrames


The two primary components of pandas are the Series and the DataFrame.

A Series is essentially a column, and a DataFrame is a multi-dimensional table made up of a collection of Series.

For example, the following DataFrame is made of two Series, ages and heights

You can think of a Series as a one-dimensional array, while a DataFrame is a multi-dimensional array.



DataFrames


Before working with real data, let's first create a DataFrame manually to explore its functions.
The easiest way to create a DataFrame is using a dictionary:

data = {
   'ages': [14, 18, 24, 42],
   'heights': [165, 180, 176, 184]
} 

Each key is a column, while the value is an array representing the data for that column.

Now, we can pass this dictionary to the DataFrame constructor:


import pandas as pd

data = {
   'ages': [14, 18, 24, 42],
   'heights': [165, 180, 176, 184]
}

df = pd.DataFrame(data)
print(df)

   ages  heights
0    14      165
1    18      180
2    24      176
3    42      184


DataFrames


The DataFrame automatically creates a numeric index for each row.
We can specify a custom index, when creating the DataFrame:


import pandas as pd

data = {
   'ages': [14, 18, 24, 42],
   'heights': [165, 180, 176, 184]
}

df = pd.DataFrame(data, index=['James', 'Bob', 'Amy', 'Dave'])
print(df)

       ages  heights
James    14      165
Bob      18      180
Amy      24      176
Dave     42      184


Now we can access a row using its index and the loc[] function:


import pandas as pd

data = {
   'ages': [14, 18, 24, 42],
   'heights': [165, 180, 176, 184]
}

df = pd.DataFrame(data, index=['James', 'Bob', 'Amy', 'Dave'])
print(df.loc["Bob"])

ages        18
heights    180
Name: Bob, dtype: int64



This will output the row that corresponds to the index "Bob".
Note, that loc uses square brackets to specify the index.


Indexing


We can select a single column by specifying its name in square brackets:


import pandas as pd

data = {
   'ages': [14, 18, 24, 42],
   'heights': [165, 180, 176, 184]
}

df = pd.DataFrame(data, index=['James', 'Bob', 'Amy', 'Dave'])

print(df["ages"])

James    14
Bob      18
Amy      24
Dave     42
Name: ages, dtype: int64



The result is a Series object.

If we want to select multiple columns, we can specify a list of column names:


import pandas as pd

data = {
   'ages': [14, 18, 24, 42],
   'heights': [165, 180, 176, 184]
}

df = pd.DataFrame(data, index=['James', 'Bob', 'Amy', 'Dave'])

print(df[["ages", "heights"]])

       ages  heights
James    14      165
Bob      18      180
Amy      24      176
Dave     42      184


This time, the result is a DataFrame, as it includes multiple columns.
This is useful, when we need to select only a part of the columns from the dataset.


Slicing


Pandas uses the iloc function to select data based on its numeric index.
It works the same way indexing lists does in Python.

For example:

import pandas as pd

data = {
   'ages': [14, 18, 24, 42],
   'heights': [165, 180, 176, 184]
}

df = pd.DataFrame(data, index=['James', 'Bob', 'Amy', 'Dave'])

# third row
print(df.iloc[2])

#first 3 rows
print(df.iloc[:3])

# rows 2 to 3
print(df.iloc[1:3])

ages        24
heights    176
Name: Amy, dtype: int64
       ages  heights
James    14      165
Bob      18      180
Amy      24      176
     ages  heights
Bob    18      180
Amy    24      176


iloc follows the same rules as slicing does with Python lists.

Slicing
Fill in the blanks to get the last 5 rows of df:


df.iloc[-5:]


49 Comments
Conditions


We can also select the data based on a condition.
For example, let's select all rows where age is greater than 18 and height is greater than 180:



import pandas as pd

data = {
   'ages': [14, 18, 24, 42],
   'heights': [165, 180, 176, 184]
}

df = pd.DataFrame(data, index=['James', 'Bob', 'Amy', 'Dave'])

print(df[(df['ages']>18) & (df['heights']>180)])

    ages  heights
Dave    42      184



Conditions
Fill in the blanks to select all rows which have rank > 10 or type equal to 42:

df[(df['rank']>10) | (df['type']==42)]



Reading Data


It is quite common for data to come in a file format. One of the most popular formats is the CSV (comma-separated values).
Pandas supports reading data from a CSV file directly into a DataFrame.

For our examples, we will use a CSV file that contains the COVID-19 infection data in California for the year 2020, called 'ca-covid.csv'.



The read_csv() function reads the data of a CSV file into a DataFrame:

df = pd.read_csv("ca-covid.csv")


We need to provide the file path to the read_csv() function.

Pandas also supports reading from JSON files, as well as SQL databases.



Reading Data


Once we have the data in a DataFrame, we can start exploring it.

We can get the first rows of the data using the head() function of the DataFrame:



import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

print(df.head())

   date       state  cases  deaths
0  25.01.20  California      1       0
1  26.01.20  California      1       0
2  27.01.20  California      0       0
3  28.01.20  California      0       0
4  29.01.20  California      0       0

By default it returns the first 5 rows. You can instruct it to return the number of rows you would like as an argument (for example, df.head(10) will return the first 10 rows).

We can see that our DataFrame contains the date, state, number of cases and deaths for that date.
Similarly, you can get the last rows using the tail() function.


Reading Data


The info() function is used to get essential information about your dataset, such as number of rows, columns, data types, etc:


import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.info()

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 342 entries, 0 to 341
Data columns (total 4 columns):
 #   Column  Non-Null Count  Dtype 
---  ------  --------------  ----- 
 0   date    342 non-null    object
 1   state   342 non-null    object
 2   cases   342 non-null    int64 
 3   deaths  342 non-null    int64 
dtypes: int64(2), object(2)
memory usage: 10.8+ KB



From the result, we can see that our dataset contains 342 rows and 4 columns: date, state, cases, deaths.

We also see that Pandas has added an auto generated index.
We can set our own index column by using the set_index() function:


import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.set_index("date", inplace=True)

print(df.head())

               state  cases  deaths
date                               
25.01.20  California      1       0
26.01.20  California      1       0
27.01.20  California      0       0
28.01.20  California      0       0
29.01.20  California      0       0


The date column is a good choice for our index, as there is one row for each date.
The inplace=True argument specifies that the change will be applied to our DataFrame, without the need to assign it to a new DataFrame variable.


Dropping a Column


Since our data is only for the state of California, we can remove that column from our DataFrame, as it contains the same value for all rows:

import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.set_index('date', inplace=True)
df.drop('state', axis=1, inplace=True)

df.info()


<class 'pandas.core.frame.DataFrame'>
Index: 342 entries, 25.01.20 to 31.12.20
Data columns (total 2 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   cases   342 non-null    int64
 1   deaths  342 non-null    int64
dtypes: int64(2)
memory usage: 8.0+ KB


drop() deletes rows and columns.
axis=1 specifies that we want to drop a column.
axis=0 will drop a row.
Now our dataset is much cleaner: we have a date index, and casesdeaths columns.

Dropping a Column

Fill in the blanks to drop the column 'extra' from df:

df.drop('extra', axis=1, inplace=True)


#####################################################################################################


Creating Columns


Pandas allows us to create our own columns.
For example, we can add a month column based on the date column:


import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.drop('state', axis=1, inplace=True)

df['month'] = pd.to_datetime(df['date'], format="%d.%m.%y").dt.month_name()

df.set_index('date', inplace=True)

print(df.head())


      cases  deaths    month
date                            
25.01.20      1       0  January
26.01.20      1       0  January
27.01.20      0       0  January
28.01.20      0       0  January
29.01.20      0       0  January


We do this by converting the date column to datetime and extracting the month name from it, assigning the value to our new month column.
Our date is in DD.MM.YY format, which is why we need to specify the format attribute.

Creating Columns

Add a new column called 'area' to the df DataFrame, which should be the product of the height and width column values.

df['area'] = df['width']*df['height']



Summary Statistics


Now that our dataset is clean and set up, we are ready to look into some stats!
The describe() function returns the summary statistics for all the numeric columns:

import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.drop('state', axis=1, inplace=True)
df['month'] = pd.to_datetime(df['date'], format="%d.%m.%y").dt.month_name()
df.set_index('date', inplace=True)

print(df.describe())



              cases      deaths
count    342.000000  342.000000
mean    6747.862573   75.921053
std    10023.201267   76.639861
min        0.000000   -5.000000
25%     1352.250000   22.000000
50%     3462.500000   62.500000
75%     7637.250000  104.000000
max    64987.000000  574.000000


This function will show main statistics for the numeric columns, such as std, mean, min, max values, etc.

Run the code to see the result!
From the result, we see that the maximum cases that have been recorded in a day is 64987, while the average daily number of new cases is 6748.
We can also get the summary stats for a single column, for example:
df['cases'].describe()


Grouping


Since we have a month column, we can see how many values each month has, by using the value_counts() functions:


import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.drop('state', axis=1, inplace=True)
df['month'] = pd.to_datetime(df['date'], format="%d.%m.%y").dt.month_name()
df.set_index('date', inplace=True)

print(df['month'].value_counts())

October      31
July         31
December     31
May          31
August       31
March        31
November     30
April        30
June         30
September    30
February     29
January       7
Name: month, dtype: int64

We can see that, for example, January has only 7 records, while the other months have data for all days.
value_counts() returns how many times a value appears in the dataset, also called the frequency of the values.


Grouping


Now we can calculate data insights!
For example, let's determine the number of total infections in each month.
To do this, we need to group our data by the month column and then calculate the sum of the cases column for each month:


import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.drop('state', axis=1, inplace=True)
df['month'] = pd.to_datetime(df['date'], format="%d.%m.%y").dt.month_name()
df.set_index('date', inplace=True)

print(df.groupby('month')['cases'].sum())

month
April          41887
August        210268
December     1070577
February          25
January            3
July          270120
June          119039
March           8555
May            62644
November      301944
October       114123
September     108584
Name: cases, dtype: int64


The groupby() function is used to group our dataset by the given column.

We can also calculate the number of total cases in the entire year:


import pandas as pd

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.drop('state', axis=1, inplace=True)
df['month'] = pd.to_datetime(df['date'], format="%d.%m.%y").dt.month_name()
df.set_index('date', inplace=True)

print(df['cases'].sum())

2307769


We can see that California had 2,307,769 infection cases in 2020.
Similarly, we can use min(), max(), mean(), etc. to find the corresponding values for each group.




Fill in the blanks to read the data from the 'data.csv' file and output the first 15 rows.

import pandas as pd
df = pd.read_csv('data.csv')
print(df.head(15))


#############################################################################################################


COVID Data Analysis


You are working with the COVID dataset for California, which includes the number of cases and deaths for each day of 2020.
Find the day when the deaths/cases ratio was largest.

To do this, you need to first calculate the deaths/cases ratio and add it as a column to the DataFrame with the name 'ratio', then find the row that corresponds to the largest value.
Important: The output should be a DataFrame, containing all of the columns of the dataset for the corresponding row.





import pandas as pd

df = pd.read_csv("/usercode/files/ca-covid.csv")

df.drop('state', axis=1, inplace=True)
df.set_index('date', inplace=True)

df['ratio'] = df['deaths'] / df['cases']

y = df['ratio'].max()

print(df[df['ratio'] == y])



#############################################################################################################


Matplotlib


Matplotlib is a library used to create graphs, charts, and figures. It also provides functions to customize your figures by changing the colors, labels, etc.

To start using matplotlib, we first need to import it:
import matplotlib.pyplot as plt 


pyplot is the module we will be using to create our plots.
plt is a common name used for importing this module.


import matplotlib.pyplot as plt
import pandas as pd

s = pd.Series([18, 42, 9, 32, 81, 64, 3])
s.plot(kind='bar')
plt.savefig('plot.png')


The .plot() function is used to create a plot from the data in a Pandas Series or DataFrame.

Here is the result:


The data from the series is using the Y axis, while the index is plotted on the X axis.
As we have not provided a custom index for our data, the default numeric index is used.
plt.savefig('plot.png') is used to save and display the chart in our Code Playground.
In most environments this step is not needed, as calling the plot() function automatically displays the chart.



Line Plot


Matplotlib supports the creation of different chart types.
Let's start with the most basic one -- a line chart.
We will use the COVID-19 data from the previous module to create our charts.

Let's show the number of cases in the month of December.
To create a line chart we simply need to call the plot() function on our DataFrame, which contains the corresponding data:
Run the code to see the result!



import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df.set_index('date', inplace=True)

df[df['month']==12]['cases'].plot()
plt.savefig('plot.png')


Line Plot


We can also include multiple lines in our chart.

For example, let's also include the deaths column in our DataFrame:
Run the code to see the chart!
As you can see from the result, matplotlib automatically added a legend to show the colors of the lines for the columns.


import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df.set_index('date', inplace=True)

(df[df['month']==12])[['cases', 'deaths']].plot()
plt.savefig('plot.png')

As you can see from the result, matplotlib automatically added a legend to show the colors of the lines for the columns.


Bar Plot


The plot() function can take a kind argument, specifying the type of the plot we want to produce.

For bar plots, provide kind="bar".
Let's make a bar plot for the monthly infection cases:

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df.set_index('date', inplace=True)

(df.groupby('month')['cases'].sum()).plot(kind="bar")
plt.savefig('plot.png')

We first group the data by the month column, then calculate the sum of the cases in that month.


Bar Plot


We can also plot multiple columns.
The stacked property can be used to specify if the bars should be stacked on top of each other.

For example:


import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df.set_index('date', inplace=True)

df = df.groupby('month')[['cases', 'deaths']].sum()
df.plot(kind="bar", stacked=True)
plt.savefig('plot.png')

We have stacked the cases and deaths for each month.
kind="barh" can be used to create a horizontal bar chart.



Box Plot


A box plot is used to visualize the distribution of values in a column, basically visualizing the result of the describe() function.

For example, let's create a box plot for the cases in June:


import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df.set_index('date', inplace=True)

df[df["month"]==6]["cases"].plot(kind="box")
plt.savefig('plot.png')


The green line shows the median value.
The box shows the upper and lower quartiles (25% of the data is greater or less than these values).
The circles show the outliers, while the black lines show the min/max values excluding the outliers.
Check out the following article for more information on box plots: Box plots


Histogram


Similar to box plots, histograms show the distribution of data.
Visually histograms are similar to bar charts, however, histograms display frequencies for a group of data rather than an individual data point; therefore, no spaces are present between the bars.

Typically, a histogram groups data into chunks (or bins).

For example:
df[df["month"]==6]["cases"].plot(kind="hist") 

The histogram grouped the data into 9 bins and shows their frequency. You can see that, for example, only single data points are greater than 6000.
You can manually specify the number of bins to use using the bins attribute: plot(kind="hist", bins = 10)


Histogram
Fill in the blanks to create a histogram with 10 bins from the df DataFrame.

df.plot(kind="hist", bins=10)


Area Plot


kind='area' creates an Area plot:

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df.set_index('date', inplace=True)

df[df["month"]==6][["cases", "deaths"]].plot(kind="area", stacked=False)
plt.savefig('plot.png')


Scatter Plot


A scatter plot is used to show the relationship between two variables.

For example, we can visualize how the cases/deaths are related:

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df.set_index('date', inplace=True)

df[df["month"]==6][["cases", "deaths"]].plot(kind="scatter", x='cases', y='deaths')
plt.savefig('plot.png')

The plot contains 30 points since we used the data for each day in June.
The data points look "scattered" around the graph, giving this type of data visualization its name.


Pie Chart


We can create a pie chart using kind="pie".
Let's create one for cases by month:


import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")
df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = (df['date'].dt.month_name()).str[:3]
df.set_index('date', inplace=True)

df.groupby('month')['cases'].sum().plot(kind="pie")
plt.savefig('plot.png')

Pie charts are generally used to show percentage or proportional data.
Pie charts are usually used when you have up to 6 categories.


Pie Chart
We have added a 'weekday' column to our DataFrame. 
Fill in the blanks to create a pie chart, showing the number of cases for each week day:

df = df.groupby('weekday')
df['cases'].sum().plot(kind="pie")


Plot Formatting


Matplotlib provides a number of arguments to customize your plot.
The legend argument specifies whether or not to show the legend.
You can also change the labels of the axis by setting the xlabel and ylabel arguments:


import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df.set_index('day', inplace=True)

df = df[df['month']==6]

df[['cases', 'deaths']].plot(kind="line", legend=True)
plt.xlabel('Days in June')
plt.ylabel('Number')
plt.savefig('plot.png')


By default, pandas select the index name as xlabel, while leaving it empty for ylabel.


Plot Formatting


The suptitle() function can be used to set a plot title:


import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df.set_index('day', inplace=True)

df = df[df['month']==6]

df[['cases', 'deaths']].plot(kind="area", legend=True)
plt.xlabel('Days in June')
plt.ylabel('Number')
plt.suptitle("COVID-19 in June")
plt.savefig('plot.png')


We can also change the colors used in the plot by setting the color attribute. It accepts a list of color hexes.

For example, let's set the cases to blue, deaths to red colors:

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("https://www.sololearn.com/uploads/ca-covid.csv")

df.drop('state', axis=1, inplace=True)
df['date'] = pd.to_datetime(df['date'], format="%d.%m.%y")
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df.set_index('day', inplace=True)

df = df[df['month']==6]

df[['cases', 'deaths']].plot(kind="area", legend=True, stacked=False, color=['#1970E7', '#E73E19'])
plt.xlabel('Days in June')
plt.ylabel('Number')
plt.suptitle("COVID-19 in June")
plt.savefig('plot.png')

These attributes work for almost all chart types.


